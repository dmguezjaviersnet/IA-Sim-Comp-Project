from lexer import Lexer
from parser.own_token import Token_Type

orbsim_lexer = Lexer([
    ('loop', Token_Type.loop),
    ('func', Token_Type.func),
    ('if', Token_Type.if_orbsim),
    ('then', Token_Type.then),
    ('else', Token_Type.else_orbsim),
    ('let', Token_Type.let),
    ('ret', Token_Type.return_orbsim),
    ('make', Token_Type.make_orbsim),
    ('class', Token_Type.class_orbsim),
    ('print', Token_Type.print_orbsim),
    ('continue', Token_Type.continue_orbsim),
    ('break', Token_Type.break_orbsim),
    ('true|false', Token_Type.boolean),
    ('([a-z])([a-z]|[A-Z]|[0-9]|_)*', Token_Type.id_orbsim),
    ("([A-Z])([a-z]|[A-Z])*", Token_Type.type_id_orbsim),
    ('0|([1-9][0-9]*)', Token_Type.int),
    ('(0|([1-9][0-9]*)).[0-9]+', Token_Type.float),
    ('\' ((\ ) | [!-~])* \'', Token_Type.string), #  ACII(character code 33-126)
    ('\+', Token_Type.plus),
    ('\-', Token_Type.minus),
    ('\*', Token_Type.mul),
    ('/', Token_Type.div),
    ('%', Token_Type.mod),
    ('=', Token_Type.assign),
    ('==', Token_Type.equals),
    ('!=', Token_Type.not_equals),
    ('!', Token_Type.neg),
    ('<', Token_Type.less_than),
    ('>', Token_Type.greater_than),
    ('<=', Token_Type.less_or_equal_than),
    ('>=', Token_Type.greater_or_equal_than),
    ('\|\|', Token_Type.logical_or),
    ('&&', Token_Type.logical_and),
    ('\|', Token_Type.bitwise_or),
    ('^', Token_Type.bitwise_not),
    ('&', Token_Type.bitwise_and),
    ('<<', Token_Type.bitwise_shift_left),
    ('>>', Token_Type.bitwise_shift_right),
    ('\(', Token_Type.open_parenthesis),
    ('\)', Token_Type.closed_parenthesis),
    ('{', Token_Type.open_curly_braces),
    ('}', Token_Type.closed_curly_braces),
    (';', Token_Type.stmt_separator),
    (',', Token_Type.expr_separator),
    ('(\\ )+', Token_Type.space),
    ('(\\n)+', Token_Type.new_line)],
    # ('[!-~]+', Token_Type.error)], # ACII(character code 33-126) token especial para detectar los errores
    eof=Token_Type.eof)